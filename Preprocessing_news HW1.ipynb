{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Hfbb2nzl9DZ"
   },
   "source": [
    "# Pre-processing News Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T1elcGz7huoP"
   },
   "source": [
    "## Bài toán\n",
    "Dữ liệu gồm n văn bản phân vào 10 chủ đề khác nhau. Cần biễu diễn mỗi văn bản dưới dạng một vector số thể hiện cho nội dụng của văn bản đó."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lyy4DDvuhuoU"
   },
   "source": [
    "## Mục lục\n",
    "- Load dữ liệu từ thư mục\n",
    "- Loại bỏ các stop words\n",
    "- Sử dụng thư viện để mã hóa TF-IDF cho mỗi văn bản"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-_akck0KhuoW"
   },
   "source": [
    "## Phương pháp mã hóa: TF-IDF\n",
    "Cho tập gồm $n$ văn bản: $D = \\{d_1, d_2, ... d_n\\}$. Tập từ điển tương ứng được xây dựng từ $n$ văn bản này có độ dài là $m$\n",
    "- Xét văn bản $d$ có $|d|$ từ và $t$ là một từ trong $d$. Mã hóa tf-idf của $t$ trong văn bản $d$ được biểu diễn:\n",
    "\\begin{equation}\n",
    "    \\begin{split}\n",
    "        \\text{tf}_{t, d} &= \\frac{f_t}{|d|} \\\\\n",
    "        \\text{idf}_{t, d} &= \\log\\frac{n}{n_t}, \\ \\ \\ \\ n_t = |\\{d\\in D: t\\in d\\}| \\\\\n",
    "        \\text{tf-idf}_{t d} &= \\text{tf}_{t, d} \\times \\text{idf}_{t, d}\n",
    "    \\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "- Khi đó văn bản $d$ được mã hóa là một vector $m$ chiều. Các từ xuất hiện trong d sẽ được thay bằng giá trị tf-idf tương ứng. Các từ không xuất hiện trong $d$ thì thay là 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "4eQuwrwZhuoY"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import load_files\n",
    "from pyvi import ViTokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rqNL4mwDhuoa"
   },
   "source": [
    "## Load dữ liệu từ thư mục\n",
    "\n",
    "Cấu trúc thư mục như sau \n",
    "\n",
    "- data/news_vnexpress/\n",
    "\n",
    "    - Kinh tế: \n",
    "        - bài báo 1.txt \n",
    "        - bài báo 2.txt \n",
    "    - Pháp luật\n",
    "        - bài báo 3.txt \n",
    "        - bài báo 4.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "tty49E_ohuoa"
   },
   "outputs": [],
   "source": [
    "INPUT = '/Users/tienphat/Library/CloudStorage/OneDrive-HanoiUniversityofScienceandTechnology/Documents/Machine learning/ML-homeworks/Hw1/news_vnexpress'\n",
    "os.makedirs(\"images\",exist_ok=True)  # thư mục lưu các các hình ảnh trong quá trình huấn luyện và đánh gía"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Các nhãn và số văn bản tương ứng trong dữ liệu\n",
      "----------------------------------------------\n",
      "doi-song: 120\n",
      "du-lich: 54\n",
      "phap-luat: 59\n",
      "the-thao: 173\n",
      "thoi-su: 59\n",
      "suc-khoe: 162\n",
      "giai-tri: 201\n",
      "giao-duc: 105\n",
      "kinh-doanh: 262\n",
      "khoa-hoc: 144\n",
      "-------------------------\n",
      "Tổng số văn bản: 1339\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Print header\n",
    "print('Các nhãn và số văn bản tương ứng trong dữ liệu')\n",
    "print('----------------------------------------------')\n",
    "\n",
    "n = 0\n",
    "for label in os.listdir(INPUT):\n",
    "    label_path = os.path.join(INPUT, label)\n",
    "    # Check if the item is a directory\n",
    "    if os.path.isdir(label_path):\n",
    "        num_files = len(os.listdir(label_path))\n",
    "        print(f'{label}: {num_files}')\n",
    "        n += num_files\n",
    "\n",
    "print('-------------------------')\n",
    "print(f\"Tổng số văn bản: {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "j3tycWTfhuoc",
    "outputId": "bae88ffb-a53a-4a1e-a9a5-2955b60ba8c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping:\n",
      "doi-song - 0\n",
      "du-lich - 1\n",
      "giai-tri - 2\n",
      "giao-duc - 3\n",
      "khoa-hoc - 4\n",
      "kinh-doanh - 5\n",
      "phap-luat - 6\n",
      "suc-khoe - 7\n",
      "the-thao - 8\n",
      "thoi-su - 9\n",
      "--------------------------\n",
      "['/Users/tienphat/Library/CloudStorage/OneDrive-HanoiUniversityofScienceandTechnology/Documents/Machine learning/ML-homeworks/Hw1/news_vnexpress/khoa-hoc/00133.txt']\n",
      "[4]\n",
      "['Mời độc giả đặt câu hỏi tại đây\\n']\n",
      "\n",
      "Tổng số  văn bản: 1339\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "data_train = load_files(container_path=INPUT, encoding=\"utf-8\")\n",
    "print('mapping:')\n",
    "for i in range(len(data_train.target_names)):\n",
    "    print(f'{data_train.target_names[i]} - {i}')\n",
    "\n",
    "print('--------------------------')\n",
    "print(data_train.filenames[0:1])\n",
    "# print(data_train.data[0:1])\n",
    "print(data_train.target[0:1])\n",
    "print(data_train.data[0:1])\n",
    "\n",
    "print(\"\\nTổng số  văn bản: {}\" .format( len(data_train.filenames)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HU06Y_BKhuoe"
   },
   "source": [
    "## Chuyển dữ liệu dạng text về ma trận (n x m) bằng TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I6vG0C2ima31"
   },
   "source": [
    "* Bạn cần viết đoạn mã tương ứng trong cell bên dưới. Theo các bước được gợi ý"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "Ns9j8Hgrhuof",
    "outputId": "11600006-3227-4e0e-91af-e4afd76d7fef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "số lượng stopwords: 1287\n",
      "['a_lô', 'a_ha', 'ai', 'ai_ai', 'ai_nấy', 'ai_đó', 'alô', 'amen', 'anh', 'anh_ấy']\n",
      "\n",
      "Số lượng từ trong từ điển: 13108\n",
      "Kích thước dữ liệu sau khi xử lý: (1339, 13108)\n",
      "Kích thước nhãn tương ứng: (1339,)\n"
     ]
    }
   ],
   "source": [
    "# load dữ liệu các stopwords \n",
    "stop_word=['a_lô', 'a_ha', 'ai', 'ai_ai', 'ai_nấy', 'ai_đó', 'alô', 'amen', 'anh','anh_ấy']\n",
    "num=0\n",
    "for i in data_train.data:\n",
    "    for j in i.split():\n",
    "        if j in stop_word:\n",
    "            num+=1\n",
    "print(f'số lượng stopwords: {num}')\n",
    "print(stop_word)\n",
    "# Chuyển hoá dữ liệu text về dạng vector TF \n",
    "#     - loại bỏ từ dừng\n",
    "#     - sinh từ điển\n",
    "count_vectorizer=CountVectorizer(stop_words=stop_word)\n",
    "count_vectorizer.fit(data_train.data)\n",
    "count_matrix=count_vectorizer.fit_transform(data_train.data)\n",
    "# Hàm thực hiện chuyển đổi dữ liệu text thành dữ liệu số dạng ma trận \n",
    "# Input: Dữ liệu 2 chiều dạng numpy.array, mảng nhãn id dạng numpy.array \n",
    "tfidf_transformer=TfidfTransformer()\n",
    "data_preprocessed=tfidf_transformer.fit_transform(count_matrix)\n",
    "\n",
    "\n",
    "X = data_preprocessed # thuoc tinh\n",
    "Y = data_train.target #nhan\n",
    "\n",
    "print(f\"\\nSố lượng từ trong từ điển: {len(count_vectorizer.vocabulary_)}\")\n",
    "print(f\"Kích thước dữ liệu sau khi xử lý: {X.shape}\")\n",
    "print(f\"Kích thước nhãn tương ứng: {Y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "CzIuAyLphuoi",
    "outputId": "7badd4f6-b1b2-4c6f-fd13-f43ec0f5476c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         ... 0.         0.11843162 0.        ]]\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(X[100].toarray())\n",
    "print(Y[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "apf3ulZhhuoi",
    "outputId": "d1d244bd-e0a9-445d-ecfd-530abff20bc9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 1, 0])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(X[100].toarray() != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "5FjwPJlfhuoj",
    "outputId": "6481ea2f-dcaf-45eb-e5dc-d7b157f7a896"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 81)\t0.012823375184355685\n",
      "  (0, 100)\t0.01750872879179226\n",
      "  (0, 156)\t0.01961060283814016\n",
      "  (0, 188)\t0.03981066487763974\n",
      "  (0, 269)\t0.02802162970968283\n",
      "  (0, 392)\t0.02089277842382552\n",
      "  (0, 397)\t0.028858380718548977\n",
      "  (0, 418)\t0.0412379305574467\n",
      "  (0, 662)\t0.01919505066971814\n",
      "  (0, 909)\t0.027972635927685615\n",
      "  (0, 1194)\t0.04313657347966996\n",
      "  (0, 1209)\t0.08627314695933992\n",
      "  (0, 1219)\t0.04313657347966996\n",
      "  (0, 1271)\t0.013492809584655143\n",
      "  (0, 1529)\t0.01252277036080812\n",
      "  (0, 1591)\t0.029443144291452714\n",
      "  (0, 1632)\t0.019805400051052677\n",
      "  (0, 1784)\t0.03991191606062434\n",
      "  (0, 1789)\t0.039156467646194536\n",
      "  (0, 1868)\t0.04313657347966996\n",
      "  (0, 2048)\t0.0344346430397842\n",
      "  (0, 2060)\t0.06058328565192426\n",
      "  (0, 2085)\t0.012263714907304924\n",
      "  (0, 2111)\t0.02270765919463853\n",
      "  (0, 2121)\t0.021728860265386906\n",
      "  :\t:\n",
      "  (0, 12856)\t0.027028555940706092\n",
      "  (0, 12864)\t0.02802162970968283\n",
      "  (0, 12877)\t0.03937801012229834\n",
      "  (0, 12883)\t0.03268120834775445\n",
      "  (0, 12890)\t0.06338967814433391\n",
      "  (0, 12909)\t0.013443487672683843\n",
      "  (0, 12915)\t0.055671052741889424\n",
      "  (0, 12919)\t0.06744356865073656\n",
      "  (0, 12926)\t0.27972635927685613\n",
      "  (0, 12929)\t0.01625986325570686\n",
      "  (0, 12932)\t0.020377869875602726\n",
      "  (0, 12946)\t0.025453356563118246\n",
      "  (0, 12950)\t0.03598723200440628\n",
      "  (0, 12971)\t0.015015225621772495\n",
      "  (0, 12977)\t0.04000600971255878\n",
      "  (0, 12978)\t0.0267567537261503\n",
      "  (0, 12982)\t0.012779456747888569\n",
      "  (0, 12983)\t0.038072573725451905\n",
      "  (0, 12999)\t0.01750872879179226\n",
      "  (0, 13000)\t0.011705168291761499\n",
      "  (0, 13005)\t0.03317973188230703\n",
      "  (0, 13013)\t0.02101375062808561\n",
      "  (0, 13022)\t0.028981699249658724\n",
      "  (0, 13032)\t0.043184090105385195\n",
      "  (0, 13106)\t0.11843162414955007\n"
     ]
    }
   ],
   "source": [
    "print(X[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Preprocessing_news.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
